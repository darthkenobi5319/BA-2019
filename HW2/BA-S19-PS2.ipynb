{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Set 1\n",
    "\n",
    "## BUSF-SHU 210: Business Analytics (Spring 2019)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1  Forecasting Auto Sales \n",
    "\n",
    "In this problem, we will try to predict monthly sales of an Auto Brand.\n",
    "\n",
    "The file Auto.csv contains data for the problem. Each observation is a month, from January\n",
    "2010 to February 2014. For each month, we have the following variables:\n",
    "\n",
    "* Month = the month of the year for the observation (1 = January, 2 = February, 3 = March,...).\n",
    "\n",
    "* Year = the year of the observation.\n",
    "\n",
    "* AutoSales = the number of units of the Auto sold in the United States in the given month.\n",
    "\n",
    "* Unemployment = the estimated unemployment percentage in the United States in the given month.\n",
    "\n",
    "* Queries = a (normalized) approximation of the number of Google searches for “Auto” in the given month.\n",
    "\n",
    "* CP I_energy = the monthly consumer price index (CPI) for energy for the given month.\n",
    "\n",
    "* CP I_all = the consumer price index (CPI) for all products for the given month; this is a\n",
    "    measure of the magnitude of the prices paid by consumer households for goods and services\n",
    "    (e.g., food, clothing, electricity, etc.).\n",
    "\n",
    "Load the data set into R and split the data set into training and testing sets as follows: Place all\n",
    "observations for 2012 and earlier in the training set, and all observations for 2013 and 2014 into\n",
    "the testing set. You may want to use the function subset() (use the function ?subset to figure\n",
    "out the usage of subset()).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'data.frame':\t50 obs. of  7 variables:\n",
      " $ Month       : int  1 1 1 1 1 2 2 2 2 2 ...\n",
      " $ Year        : int  2010 2011 2012 2013 2014 2010 2011 2012 2013 2014 ...\n",
      " $ ElantraSales: int  7690 9659 10900 12174 15326 7966 12289 13820 16219 16393 ...\n",
      " $ Unemployment: num  9.7 9.1 8.2 7.9 6.6 9.8 9 8.3 7.7 6.7 ...\n",
      " $ Queries     : int  153 259 354 230 232 130 266 296 239 240 ...\n",
      " $ CPI_energy  : num  213 229 244 243 248 ...\n",
      " $ CPI_all     : num  217 221 228 231 235 ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "     Month           Year       ElantraSales    Unemployment      Queries     \n",
       " Min.   : 1.0   Min.   :2010   Min.   : 7690   Min.   :6.600   Min.   :130.0  \n",
       " 1st Qu.: 3.0   1st Qu.:2011   1st Qu.:12560   1st Qu.:7.725   1st Qu.:224.8  \n",
       " Median : 6.0   Median :2012   Median :15624   Median :8.250   Median :262.5  \n",
       " Mean   : 6.3   Mean   :2012   Mean   :16005   Mean   :8.422   Mean   :263.5  \n",
       " 3rd Qu.: 9.0   3rd Qu.:2013   3rd Qu.:19197   3rd Qu.:9.100   3rd Qu.:311.0  \n",
       " Max.   :12.0   Max.   :2014   Max.   :26153   Max.   :9.900   Max.   :427.0  \n",
       "   CPI_energy       CPI_all     \n",
       " Min.   :204.2   Min.   :217.3  \n",
       " 1st Qu.:230.1   1st Qu.:221.3  \n",
       " Median :244.4   Median :227.9  \n",
       " Mean   :236.9   Mean   :226.7  \n",
       " 3rd Qu.:247.1   3rd Qu.:231.7  \n",
       " Max.   :256.4   Max.   :235.2  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Read in data\n",
    "# If read is unsuccessful, change the input to the absolute path\n",
    "auto = read.csv(\"C:/Users/darth/Dropbox/Study/Study/Business Analytics/LA/HW2/Auto.csv\")\n",
    "    str(auto)\n",
    "    summary(auto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seperate the dataset into traing set and testing set\n",
    "autoTrain = subset(auto, Year <= 2012)\n",
    "autoTest = subset(auto, Year > 2012)\n",
    "# str(autoTrain)\n",
    "# summary(autoTrain)\n",
    "# str(autoTest)\n",
    "# summary(autoTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.(a) \n",
    "Build a linear regression model to predict monthly Auto sales using Unemployment, CPI_all,\n",
    "CPI_energy and Queries as the independent variables. Use all of the training set data to do this.\n",
    "\n",
    "Please show a screen shot of your linear regression model using the “summary” function. Clearly\n",
    "state the significance, the sign, and the magnitude of the association between the dependent variable and each independent variable.\n",
    "\n",
    "## Solution 1.(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "lm(formula = ElantraSales ~ Unemployment + CPI_all + CPI_energy + \n",
       "    Queries, data = autoTrain)\n",
       "\n",
       "Residuals:\n",
       "    Min      1Q  Median      3Q     Max \n",
       "-6785.2 -2101.8  -562.5  2901.7  7021.0 \n",
       "\n",
       "Coefficients:\n",
       "              Estimate Std. Error t value Pr(>|t|)\n",
       "(Intercept)   95385.36  170663.81   0.559    0.580\n",
       "Unemployment  -3179.90    3610.26  -0.881    0.385\n",
       "CPI_all        -297.65     704.84  -0.422    0.676\n",
       "CPI_energy       38.51     109.60   0.351    0.728\n",
       "Queries          19.03      11.26   1.690    0.101\n",
       "\n",
       "Residual standard error: 3295 on 31 degrees of freedom\n",
       "Multiple R-squared:  0.4282,\tAdjusted R-squared:  0.3544 \n",
       "F-statistic: 5.803 on 4 and 31 DF,  p-value: 0.00132\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>Month</th><th scope=col>Year</th><th scope=col>ElantraSales</th><th scope=col>Unemployment</th><th scope=col>Queries</th><th scope=col>CPI_energy</th><th scope=col>CPI_all</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>Month</th><td> 1.0000000</td><td> 0.0000000</td><td> 0.1097945</td><td>-0.2036029</td><td> 0.0158443</td><td> 0.1760198</td><td> 0.2667883</td></tr>\n",
       "\t<tr><th scope=row>Year</th><td> 0.0000000</td><td> 1.0000000</td><td> 0.5872737</td><td>-0.9587459</td><td> 0.7265310</td><td> 0.8316052</td><td> 0.9485847</td></tr>\n",
       "\t<tr><th scope=row>ElantraSales</th><td> 0.1097945</td><td> 0.5872737</td><td> 1.0000000</td><td>-0.5671458</td><td> 0.6100645</td><td> 0.5916491</td><td> 0.5936217</td></tr>\n",
       "\t<tr><th scope=row>Unemployment</th><td>-0.2036029</td><td>-0.9587459</td><td>-0.5671458</td><td> 1.0000000</td><td>-0.6411093</td><td>-0.8007188</td><td>-0.9562123</td></tr>\n",
       "\t<tr><th scope=row>Queries</th><td> 0.0158443</td><td> 0.7265310</td><td> 0.6100645</td><td>-0.6411093</td><td> 1.0000000</td><td> 0.8328381</td><td> 0.7536732</td></tr>\n",
       "\t<tr><th scope=row>CPI_energy</th><td> 0.1760198</td><td> 0.8316052</td><td> 0.5916491</td><td>-0.8007188</td><td> 0.8328381</td><td> 1.0000000</td><td> 0.9132259</td></tr>\n",
       "\t<tr><th scope=row>CPI_all</th><td> 0.2667883</td><td> 0.9485847</td><td> 0.5936217</td><td>-0.9562123</td><td> 0.7536732</td><td> 0.9132259</td><td> 1.0000000</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllllll}\n",
       "  & Month & Year & ElantraSales & Unemployment & Queries & CPI\\_energy & CPI\\_all\\\\\n",
       "\\hline\n",
       "\tMonth &  1.0000000 &  0.0000000 &  0.1097945 & -0.2036029 &  0.0158443 &  0.1760198 &  0.2667883\\\\\n",
       "\tYear &  0.0000000 &  1.0000000 &  0.5872737 & -0.9587459 &  0.7265310 &  0.8316052 &  0.9485847\\\\\n",
       "\tElantraSales &  0.1097945 &  0.5872737 &  1.0000000 & -0.5671458 &  0.6100645 &  0.5916491 &  0.5936217\\\\\n",
       "\tUnemployment & -0.2036029 & -0.9587459 & -0.5671458 &  1.0000000 & -0.6411093 & -0.8007188 & -0.9562123\\\\\n",
       "\tQueries &  0.0158443 &  0.7265310 &  0.6100645 & -0.6411093 &  1.0000000 &  0.8328381 &  0.7536732\\\\\n",
       "\tCPI\\_energy &  0.1760198 &  0.8316052 &  0.5916491 & -0.8007188 &  0.8328381 &  1.0000000 &  0.9132259\\\\\n",
       "\tCPI\\_all &  0.2667883 &  0.9485847 &  0.5936217 & -0.9562123 &  0.7536732 &  0.9132259 &  1.0000000\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | Month | Year | ElantraSales | Unemployment | Queries | CPI_energy | CPI_all | \n",
       "|---|---|---|---|---|---|---|\n",
       "| Month |  1.0000000 |  0.0000000 |  0.1097945 | -0.2036029 |  0.0158443 |  0.1760198 |  0.2667883 | \n",
       "| Year |  0.0000000 |  1.0000000 |  0.5872737 | -0.9587459 |  0.7265310 |  0.8316052 |  0.9485847 | \n",
       "| ElantraSales |  0.1097945 |  0.5872737 |  1.0000000 | -0.5671458 |  0.6100645 |  0.5916491 |  0.5936217 | \n",
       "| Unemployment | -0.2036029 | -0.9587459 | -0.5671458 |  1.0000000 | -0.6411093 | -0.8007188 | -0.9562123 | \n",
       "| Queries |  0.0158443 |  0.7265310 |  0.6100645 | -0.6411093 |  1.0000000 |  0.8328381 |  0.7536732 | \n",
       "| CPI_energy |  0.1760198 |  0.8316052 |  0.5916491 | -0.8007188 |  0.8328381 |  1.0000000 |  0.9132259 | \n",
       "| CPI_all |  0.2667883 |  0.9485847 |  0.5936217 | -0.9562123 |  0.7536732 |  0.9132259 |  1.0000000 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "             Month      Year       ElantraSales Unemployment Queries   \n",
       "Month         1.0000000  0.0000000  0.1097945   -0.2036029    0.0158443\n",
       "Year          0.0000000  1.0000000  0.5872737   -0.9587459    0.7265310\n",
       "ElantraSales  0.1097945  0.5872737  1.0000000   -0.5671458    0.6100645\n",
       "Unemployment -0.2036029 -0.9587459 -0.5671458    1.0000000   -0.6411093\n",
       "Queries       0.0158443  0.7265310  0.6100645   -0.6411093    1.0000000\n",
       "CPI_energy    0.1760198  0.8316052  0.5916491   -0.8007188    0.8328381\n",
       "CPI_all       0.2667883  0.9485847  0.5936217   -0.9562123    0.7536732\n",
       "             CPI_energy CPI_all   \n",
       "Month         0.1760198  0.2667883\n",
       "Year          0.8316052  0.9485847\n",
       "ElantraSales  0.5916491  0.5936217\n",
       "Unemployment -0.8007188 -0.9562123\n",
       "Queries       0.8328381  0.7536732\n",
       "CPI_energy    1.0000000  0.9132259\n",
       "CPI_all       0.9132259  1.0000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Build a linear regression model using Unemployment, CPI_all, CPI_energy and Queries\n",
    "# dependent variable is ElantraSales\n",
    "model1 = lm(ElantraSales ~ Unemployment + CPI_all + CPI_energy + Queries, data = autoTrain)\n",
    "summary(model1)\n",
    "cor(autoTrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.(b)\n",
    "\n",
    "We would now like to improve the model by incorporating seasonality. Seasonality refers to the fact that demand is often cyclical/periodic in time. For example, demand for warm outerwear (like jackets and coats) is higher in fall/autumn and winter than in spring and summer.\n",
    "\n",
    "\n",
    "In our problem, since our data includes the month of the year in which the units were sold, it is feasible for us to incorporate monthly seasonality. From a modeling point of view, it may be reasonable that the month plays an effect in how many Auto units are sold.\n",
    "\n",
    "To incorporate the seasonal effect due to the month, build a new linear regression model that predicts monthly Auto sales using Month as well as Unemployment, CPI_all, CPI_energy and Queries. Do not modify the training and testing data frames before building the model. Based on the model estimation results, how do you evaluate the new model compared with the original one?\n",
    "\n",
    "## Solution 1(b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "lm(formula = ElantraSales ~ Unemployment + CPI_all + CPI_energy + \n",
       "    Queries + Month, data = autoTrain)\n",
       "\n",
       "Residuals:\n",
       "    Min      1Q  Median      3Q     Max \n",
       "-6416.6 -2068.7  -597.1  2616.3  7183.2 \n",
       "\n",
       "Coefficients:\n",
       "              Estimate Std. Error t value Pr(>|t|)  \n",
       "(Intercept)  148330.49  195373.51   0.759   0.4536  \n",
       "Unemployment  -4137.28    4008.56  -1.032   0.3103  \n",
       "CPI_all        -517.99     808.26  -0.641   0.5265  \n",
       "CPI_energy       54.18     114.08   0.475   0.6382  \n",
       "Queries          21.19      11.98   1.769   0.0871 .\n",
       "Month           110.69     191.66   0.578   0.5679  \n",
       "---\n",
       "Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
       "\n",
       "Residual standard error: 3331 on 30 degrees of freedom\n",
       "Multiple R-squared:  0.4344,\tAdjusted R-squared:  0.3402 \n",
       "F-statistic: 4.609 on 5 and 30 DF,  p-value: 0.003078\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Build a linear regression model using Unemployment, CPI_all, CPI_energy, Queries and month\n",
    "# dependent variable is ElantraSales\n",
    "model2 = lm(ElantraSales ~ Unemployment + CPI_all + CPI_energy + Queries + Month, data = autoTrain)\n",
    "summary(model2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although our in-sample $R^{2}$ shows that the second model is a better fit, we need to use the testing set to calculate out-of-sample $R^{2}$\n",
    "\n",
    "**The out-of-sample fit is measured by the $R^{2}$**\n",
    "\n",
    "The formula for $R^{2}$ is:\n",
    "\n",
    "$\n",
    "R^{2} = 1 - \\frac{\\text{SSE}}{\\text{SST}} \n",
    "$\n",
    "\n",
    "And SSE (Sum of Squared Errors) is :\n",
    "\n",
    "$\n",
    "SSE = \\displaystyle\\sum_{i=1}^{n} ({Y}_{i}-\\hat{Y})^{2}\n",
    "$\n",
    "\n",
    "And SST (Sum of Squared Total) is :\n",
    "\n",
    "$\n",
    "SSE = \\displaystyle\\sum_{i=1}^{n}(Y_{i} - \\bar{Y}_{\\text{train}})^{2}\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.497511590027953"
      ],
      "text/latex": [
       "0.497511590027953"
      ],
      "text/markdown": [
       "0.497511590027953"
      ],
      "text/plain": [
       "[1] 0.4975116"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.466234392151345"
      ],
      "text/latex": [
       "0.466234392151345"
      ],
      "text/markdown": [
       "0.466234392151345"
      ],
      "text/plain": [
       "[1] 0.4662344"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make test set predictions\n",
    "predictTest1 = predict(model1, newdata=autoTest)\n",
    "predictTest2 = predict(model2, newdata=autoTest)\n",
    "\n",
    "\n",
    "# Compute R-squared\n",
    "SSE1 = sum((autoTest$ElantraSales - predictTest1)^2)\n",
    "SST = sum((autoTest$ElantraSales - mean(autoTrain$ElantraSales))^2)\n",
    "Rsquared1 = 1 - SSE1/SST\n",
    "Rsquared1\n",
    "\n",
    "SSE2 = sum((autoTest$ElantraSales - predictTest2)^2)\n",
    "SST = sum((autoTest$ElantraSales - mean(autoTrain$ElantraSales))^2)\n",
    "Rsquared2 = 1 - SSE2/SST\n",
    "\n",
    "\n",
    "\n",
    "Rsquared2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the first model has the better **out-of-sample** fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.(c)\n",
    " In the new model, given two monthly periods that are otherwise identical in Unemployment, CPI_all, CPI_energy and Queries, what is the absolute difference in predicted Auto sales given that one period is in January and one is in March? \n",
    " \n",
    " **221.38**\n",
    " \n",
    " \n",
    " Consider again the new model, given two monthly periods that are otherwise identical in Unemployment, CPI_all, CPI_energy and Queries, what is the absolute difference in predicted Auto sales given that one period is in January and one is in\n",
    "May? \n",
    "\n",
    "**442.76**\n",
    "\n",
    "Is there anything you feel uncomfortable about this finding?\n",
    "\n",
    "**As month increases, sales increase monotonically. This is because we are treating months as numerical values, and the monthes are not \"equal\". We would need to treat them as categorical values **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.(d)\n",
    "\n",
    "Alternatively, we consider Month as a factor variable, instead of a numeric variable. Then, we can use the binary variable technique introduced in Problem 2 of Homework 1 to build a linear regression model. \n",
    "\n",
    "Why do you think we should use the factor variable instead of the numeric variable to represent month? To convert a numeric variable into a factor variable, you may use the function as.factor(). To apply this function, you may type:\n",
    "\n",
    "Auto_train\\$MonthF=as.factor(Auto_train\\$Month) and Auto_test\\$MonthF=as.factor(Auto_test\\$Month) in the Jupyter Notebook or R console. \n",
    "\n",
    "In this way, you will not overwrite the original numeric variable Month.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "lm(formula = ElantraSales ~ Unemployment + CPI_all + CPI_energy + \n",
       "    Queries + MonthF, data = autoTrain)\n",
       "\n",
       "Residuals:\n",
       "    Min      1Q  Median      3Q     Max \n",
       "-3865.1 -1211.7   -77.1  1207.5  3562.2 \n",
       "\n",
       "Coefficients:\n",
       "               Estimate Std. Error t value Pr(>|t|)    \n",
       "(Intercept)  312509.280 144061.867   2.169 0.042288 *  \n",
       "Unemployment  -7739.381   2968.747  -2.607 0.016871 *  \n",
       "CPI_all       -1343.307    592.919  -2.266 0.034732 *  \n",
       "CPI_energy      288.631     97.974   2.946 0.007988 ** \n",
       "Queries          -4.764     12.938  -0.368 0.716598    \n",
       "MonthF2        2254.998   1943.249   1.160 0.259540    \n",
       "MonthF3        6696.557   1991.635   3.362 0.003099 ** \n",
       "MonthF4        7556.607   2038.022   3.708 0.001392 ** \n",
       "MonthF5        7420.249   1950.139   3.805 0.001110 ** \n",
       "MonthF6        9215.833   1995.230   4.619 0.000166 ***\n",
       "MonthF7        9929.464   2238.800   4.435 0.000254 ***\n",
       "MonthF8        7939.447   2064.629   3.845 0.001010 ** \n",
       "MonthF9        5013.287   2010.745   2.493 0.021542 *  \n",
       "MonthF10       2500.184   2084.057   1.200 0.244286    \n",
       "MonthF11       3238.932   2397.231   1.351 0.191747    \n",
       "MonthF12       5293.911   2228.310   2.376 0.027621 *  \n",
       "---\n",
       "Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
       "\n",
       "Residual standard error: 2306 on 20 degrees of freedom\n",
       "Multiple R-squared:  0.8193,\tAdjusted R-squared:  0.6837 \n",
       "F-statistic: 6.044 on 15 and 20 DF,  p-value: 0.0001469\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Build a linear regression model using Unemployment, CPI_all, CPI_energy, Queries and month\n",
    "# dependent variable is ElantraSales\n",
    "autoTrain$MonthF = as.factor(autoTrain$Month)\n",
    "autoTest$MonthF = as.factor(autoTest$Month)\n",
    "model3 = lm(ElantraSales ~ Unemployment + CPI_all + CPI_energy + Queries + MonthF, data = autoTrain)\n",
    "summary(model3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.(e) \n",
    "\n",
    "Re-run the regression with the Month variable modeled as a factor variable. (Create a new variable that models the Month as a factor. From the new regression results, what seasonality pattern have you observed?\n",
    "\n",
    "**See the summary above**\n",
    "\n",
    "\n",
    "## 1.(f) \n",
    "\n",
    "Another peculiar observation about the regression results (with month as a factor variable) is that the signs of the Queries variable and the CPI_energy variable. Why their signs are counterintuitive? Please try to give an explanation for such phenomenon and find a way to address this issue. You may need to remove some independent variables and re-build the linear regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "lm(formula = ElantraSales ~ Unemployment + MonthF, data = autoTrain)\n",
       "\n",
       "Residuals:\n",
       "    Min      1Q  Median      3Q     Max \n",
       "-4305.5 -1390.5    30.9   992.5  6025.0 \n",
       "\n",
       "Coefficients:\n",
       "             Estimate Std. Error t value Pr(>|t|)    \n",
       "(Intercept)   42541.4     6577.8   6.467 1.34e-06 ***\n",
       "Unemployment  -3680.6      709.4  -5.188 2.93e-05 ***\n",
       "MonthF2        2064.7     2239.4   0.922  0.36611    \n",
       "MonthF3        6426.7     2239.4   2.870  0.00866 ** \n",
       "MonthF4        7026.7     2239.8   3.137  0.00462 ** \n",
       "MonthF5        6559.6     2239.8   2.929  0.00755 ** \n",
       "MonthF6        7512.9     2240.4   3.353  0.00275 ** \n",
       "MonthF7        7518.3     2240.4   3.356  0.00274 ** \n",
       "MonthF8        6167.6     2241.3   2.752  0.01136 *  \n",
       "MonthF9        3975.9     2245.4   1.771  0.08987 .  \n",
       "MonthF10       1815.8     2249.4   0.807  0.42778    \n",
       "MonthF11       1924.9     2247.2   0.857  0.40054    \n",
       "MonthF12       4159.8     2257.2   1.843  0.07827 .  \n",
       "---\n",
       "Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
       "\n",
       "Residual standard error: 2743 on 23 degrees of freedom\n",
       "Multiple R-squared:  0.706,\tAdjusted R-squared:  0.5526 \n",
       "F-statistic: 4.602 on 12 and 23 DF,  p-value: 0.0008367\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model4 = lm(ElantraSales ~  Unemployment + MonthF, data = autoTrain)\n",
    "summary(model4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.(f) \n",
    "Use out-of-sample test to evaluate all your models built to estimate the sales of Auto. Report the out-of-sample R2 of each model and discuss which model you would like recommend to\n",
    "this Auto Brand for their sales forecasting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.742690155183046"
      ],
      "text/latex": [
       "0.742690155183046"
      ],
      "text/markdown": [
       "0.742690155183046"
      ],
      "text/plain": [
       "[1] 0.7426902"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.879316664693605"
      ],
      "text/latex": [
       "0.879316664693605"
      ],
      "text/markdown": [
       "0.879316664693605"
      ],
      "text/plain": [
       "[1] 0.8793167"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictTest3 = predict(model3, newdata=autoTest)\n",
    "predictTest4 = predict(model4, newdata=autoTest)\n",
    "\n",
    "SSE3 = sum((autoTest$ElantraSales - predictTest3)^2)\n",
    "SSE4 = sum((autoTest$ElantraSales - predictTest4)^2)\n",
    "\n",
    "Rsquared3 = 1 - SSE3/SST\n",
    "Rsquared3\n",
    "Rsquared4 = 1 - SSE4/SST\n",
    "Rsquared4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Therefore, we recommend model 4 because it has the best out-of-sample R squared**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2. Election Forecasting\n",
    "\n",
    "In this problem, you will use polling data from the months leading up to a presidential election to predict the winner by logistic regression. The file polling.csv contains the polling data for United States Presidential Election in 2004, 2008 and 2012. \n",
    "\n",
    "The variables are listed as follows: \n",
    "* State: Name of state • Y ear: Election year (2004, 2008, 2012) \n",
    "\n",
    "* Rasmussen and SurveyUSA: Voters who said they were likely to vote Republican % voters who said they were likely to vote Democrat %, from two major polling data resources, Rasmussen and SurveyUSA. \n",
    "\n",
    "* DiffCount: Number of polls that predicted a Republican winner in the state - number of polls that predicted a Democratic winner \n",
    "\n",
    "* PropR: The proportion of all polls that predicted a Republican winner \n",
    "\n",
    "* Republican: Whether a Republican actually won that state in that particular election year (1/0) \n",
    "\n",
    "Please solve the following questions. \n",
    "\n",
    "## 2.(a)\n",
    "\n",
    "Read the data set polling.csv into R. Then, split the data into a training set, consisting of all the observations in 2004 and 2008, and a testing set consisting of observations in 2012.\n",
    "\n",
    "Based on the training data set, let the baseline model be that we predict the outcome of 2012 election in each state will be the same as the outcome of 2008 election. Please Evaluate the false positive rate, the false negative rate, and the accuracy of the baseline model.\n",
    "\n",
    "## Solution 2.(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'data.frame':\t145 obs. of  7 variables:\n",
      " $ State     : Factor w/ 50 levels \"Alabama\",\"Alaska\",..: 1 1 2 2 3 3 3 4 4 4 ...\n",
      " $ Year      : int  2004 2008 2004 2008 2004 2008 2012 2004 2008 2012 ...\n",
      " $ Rasmussen : int  11 21 NA 16 5 5 8 7 10 NA ...\n",
      " $ SurveyUSA : int  18 25 NA NA 15 NA NA 5 NA NA ...\n",
      " $ DiffCount : int  5 5 1 6 8 9 4 8 5 2 ...\n",
      " $ PropR     : num  1 1 1 1 1 ...\n",
      " $ Republican: int  1 1 1 1 1 1 1 1 1 1 ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "         State          Year        Rasmussen          SurveyUSA       \n",
       " Arizona    :  3   Min.   :2004   Min.   :-41.0000   Min.   :-33.0000  \n",
       " Arkansas   :  3   1st Qu.:2004   1st Qu.: -8.0000   1st Qu.:-11.7500  \n",
       " California :  3   Median :2008   Median :  1.0000   Median : -2.0000  \n",
       " Colorado   :  3   Mean   :2008   Mean   :  0.0404   Mean   : -0.8243  \n",
       " Connecticut:  3   3rd Qu.:2012   3rd Qu.:  8.5000   3rd Qu.:  8.0000  \n",
       " Florida    :  3   Max.   :2012   Max.   : 39.0000   Max.   : 30.0000  \n",
       " (Other)    :127                  NA's   :46         NA's   :71        \n",
       "   DiffCount           PropR          Republican    \n",
       " Min.   :-19.000   Min.   :0.0000   Min.   :0.0000  \n",
       " 1st Qu.: -6.000   1st Qu.:0.0000   1st Qu.:0.0000  \n",
       " Median :  1.000   Median :0.6250   Median :1.0000  \n",
       " Mean   : -1.269   Mean   :0.5259   Mean   :0.5103  \n",
       " 3rd Qu.:  4.000   3rd Qu.:1.0000   3rd Qu.:1.0000  \n",
       " Max.   : 11.000   Max.   :1.0000   Max.   :1.0000  \n",
       "                                                    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Read in data\n",
    "# If read is unsuccessful, change the input to the absolute path\n",
    "poll = read.csv(\"C:/Users/darth/Dropbox/Study/Study/Business Analytics/LA/HW2/PollingData.csv\")\n",
    "    str(poll)\n",
    "    summary(poll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'data.frame':\t100 obs. of  7 variables:\n",
      " $ State     : Factor w/ 50 levels \"Alabama\",\"Alaska\",..: 1 1 2 2 3 3 4 4 5 5 ...\n",
      " $ Year      : int  2004 2008 2004 2008 2004 2008 2004 2008 2004 2008 ...\n",
      " $ Rasmussen : int  11 21 NA 16 5 5 7 10 -11 -27 ...\n",
      " $ SurveyUSA : int  18 25 NA NA 15 NA 5 NA -11 -24 ...\n",
      " $ DiffCount : int  5 5 1 6 8 9 8 5 -8 -5 ...\n",
      " $ PropR     : num  1 1 1 1 1 1 1 1 0 0 ...\n",
      " $ Republican: int  1 1 1 1 1 1 1 1 0 0 ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "        State         Year        Rasmussen          SurveyUSA       \n",
       " Alabama   : 2   Min.   :2004   Min.   :-41.0000   Min.   :-33.0000  \n",
       " Alaska    : 2   1st Qu.:2004   1st Qu.:-10.0000   1st Qu.:-11.0000  \n",
       " Arizona   : 2   Median :2006   Median :  1.0000   Median : -1.0000  \n",
       " Arkansas  : 2   Mean   :2006   Mean   :  0.2467   Mean   :  0.1579  \n",
       " California: 2   3rd Qu.:2008   3rd Qu.:  9.0000   3rd Qu.: 12.0000  \n",
       " Colorado  : 2   Max.   :2008   Max.   : 39.0000   Max.   : 30.0000  \n",
       " (Other)   :88                  NA's   :23         NA's   :43        \n",
       "   DiffCount          PropR          Republican  \n",
       " Min.   :-19.00   Min.   :0.0000   Min.   :0.00  \n",
       " 1st Qu.: -5.25   1st Qu.:0.0000   1st Qu.:0.00  \n",
       " Median :  1.00   Median :0.6458   Median :1.00  \n",
       " Mean   : -0.88   Mean   :0.5383   Mean   :0.53  \n",
       " 3rd Qu.:  4.00   3rd Qu.:1.0000   3rd Qu.:1.00  \n",
       " Max.   : 11.00   Max.   :1.0000   Max.   :1.00  \n",
       "                                                 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'data.frame':\t45 obs. of  7 variables:\n",
      " $ State     : Factor w/ 50 levels \"Alabama\",\"Alaska\",..: 3 4 5 6 7 9 10 11 12 13 ...\n",
      " $ Year      : int  2012 2012 2012 2012 2012 2012 2012 2012 2012 2012 ...\n",
      " $ Rasmussen : int  8 NA NA 3 -7 2 NA NA NA NA ...\n",
      " $ SurveyUSA : int  NA NA -14 -2 -13 0 8 NA NA NA ...\n",
      " $ DiffCount : int  4 2 -6 -5 -8 6 4 -2 1 -5 ...\n",
      " $ PropR     : num  0.833 1 0 0.308 0 ...\n",
      " $ Republican: int  1 1 0 0 0 0 1 0 1 0 ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "         State         Year        Rasmussen          SurveyUSA      \n",
       " Arizona    : 1   Min.   :2012   Min.   :-19.0000   Min.   :-29.000  \n",
       " Arkansas   : 1   1st Qu.:2012   1st Qu.: -5.0000   1st Qu.:-13.000  \n",
       " California : 1   Median :2012   Median :  0.0000   Median : -4.000  \n",
       " Colorado   : 1   Mean   :2012   Mean   : -0.6818   Mean   : -4.118  \n",
       " Connecticut: 1   3rd Qu.:2012   3rd Qu.:  5.2500   3rd Qu.:  5.000  \n",
       " Florida    : 1   Max.   :2012   Max.   : 14.0000   Max.   : 14.000  \n",
       " (Other)    :39                  NA's   :23         NA's   :28       \n",
       "   DiffCount           PropR          Republican    \n",
       " Min.   :-16.000   Min.   :0.0000   Min.   :0.0000  \n",
       " 1st Qu.: -6.000   1st Qu.:0.0000   1st Qu.:0.0000  \n",
       " Median : -2.000   Median :0.4000   Median :0.0000  \n",
       " Mean   : -2.133   Mean   :0.4985   Mean   :0.4667  \n",
       " 3rd Qu.:  2.000   3rd Qu.:1.0000   3rd Qu.:1.0000  \n",
       " Max.   :  8.000   Max.   :1.0000   Max.   :1.0000  \n",
       "                                                    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>Arizona</li>\n",
       "\t<li>Arkansas</li>\n",
       "\t<li>California</li>\n",
       "\t<li>Colorado</li>\n",
       "\t<li>Connecticut</li>\n",
       "\t<li>Florida</li>\n",
       "\t<li>Georgia</li>\n",
       "\t<li>Hawaii</li>\n",
       "\t<li>Idaho</li>\n",
       "\t<li>Illinois</li>\n",
       "\t<li>Indiana</li>\n",
       "\t<li>Iowa</li>\n",
       "\t<li>Kansas</li>\n",
       "\t<li>Kentucky</li>\n",
       "\t<li>Louisiana</li>\n",
       "\t<li>Maine</li>\n",
       "\t<li>Maryland</li>\n",
       "\t<li>Massachusetts</li>\n",
       "\t<li>Michigan</li>\n",
       "\t<li>Minnesota</li>\n",
       "\t<li>Mississippi</li>\n",
       "\t<li>Missouri</li>\n",
       "\t<li>Montana</li>\n",
       "\t<li>Nebraska</li>\n",
       "\t<li>Nevada</li>\n",
       "\t<li>New Hampshire</li>\n",
       "\t<li>New Jersey</li>\n",
       "\t<li>New Mexico</li>\n",
       "\t<li>New York</li>\n",
       "\t<li>North Carolina</li>\n",
       "\t<li>North Dakota</li>\n",
       "\t<li>Ohio</li>\n",
       "\t<li>Oklahoma</li>\n",
       "\t<li>Oregon</li>\n",
       "\t<li>Pennsylvania</li>\n",
       "\t<li>Rhode Island</li>\n",
       "\t<li>South Carolina</li>\n",
       "\t<li>South Dakota</li>\n",
       "\t<li>Tennessee</li>\n",
       "\t<li>Texas</li>\n",
       "\t<li>Utah</li>\n",
       "\t<li>Virginia</li>\n",
       "\t<li>Washington</li>\n",
       "\t<li>West Virginia</li>\n",
       "\t<li>Wisconsin</li>\n",
       "</ol>\n",
       "\n",
       "<details>\n",
       "\t<summary style=display:list-item;cursor:pointer>\n",
       "\t\t<strong>Levels</strong>:\n",
       "\t</summary>\n",
       "\t<ol class=list-inline>\n",
       "\t\t<li>'Alabama'</li>\n",
       "\t\t<li>'Alaska'</li>\n",
       "\t\t<li>'Arizona'</li>\n",
       "\t\t<li>'Arkansas'</li>\n",
       "\t\t<li>'California'</li>\n",
       "\t\t<li>'Colorado'</li>\n",
       "\t\t<li>'Connecticut'</li>\n",
       "\t\t<li>'Delaware'</li>\n",
       "\t\t<li>'Florida'</li>\n",
       "\t\t<li>'Georgia'</li>\n",
       "\t\t<li>'Hawaii'</li>\n",
       "\t\t<li>'Idaho'</li>\n",
       "\t\t<li>'Illinois'</li>\n",
       "\t\t<li>'Indiana'</li>\n",
       "\t\t<li>'Iowa'</li>\n",
       "\t\t<li>'Kansas'</li>\n",
       "\t\t<li>'Kentucky'</li>\n",
       "\t\t<li>'Louisiana'</li>\n",
       "\t\t<li>'Maine'</li>\n",
       "\t\t<li>'Maryland'</li>\n",
       "\t\t<li>'Massachusetts'</li>\n",
       "\t\t<li>'Michigan'</li>\n",
       "\t\t<li>'Minnesota'</li>\n",
       "\t\t<li>'Mississippi'</li>\n",
       "\t\t<li>'Missouri'</li>\n",
       "\t\t<li>'Montana'</li>\n",
       "\t\t<li>'Nebraska'</li>\n",
       "\t\t<li>'Nevada'</li>\n",
       "\t\t<li>'New Hampshire'</li>\n",
       "\t\t<li>'New Jersey'</li>\n",
       "\t\t<li>'New Mexico'</li>\n",
       "\t\t<li>'New York'</li>\n",
       "\t\t<li>'North Carolina'</li>\n",
       "\t\t<li>'North Dakota'</li>\n",
       "\t\t<li>'Ohio'</li>\n",
       "\t\t<li>'Oklahoma'</li>\n",
       "\t\t<li>'Oregon'</li>\n",
       "\t\t<li>'Pennsylvania'</li>\n",
       "\t\t<li>'Rhode Island'</li>\n",
       "\t\t<li>'South Carolina'</li>\n",
       "\t\t<li>'South Dakota'</li>\n",
       "\t\t<li>'Tennessee'</li>\n",
       "\t\t<li>'Texas'</li>\n",
       "\t\t<li>'Utah'</li>\n",
       "\t\t<li>'Vermont'</li>\n",
       "\t\t<li>'Virginia'</li>\n",
       "\t\t<li>'Washington'</li>\n",
       "\t\t<li>'West Virginia'</li>\n",
       "\t\t<li>'Wisconsin'</li>\n",
       "\t\t<li>'Wyoming'</li>\n",
       "\t</ol>\n",
       "</details>"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item Arizona\n",
       "\\item Arkansas\n",
       "\\item California\n",
       "\\item Colorado\n",
       "\\item Connecticut\n",
       "\\item Florida\n",
       "\\item Georgia\n",
       "\\item Hawaii\n",
       "\\item Idaho\n",
       "\\item Illinois\n",
       "\\item Indiana\n",
       "\\item Iowa\n",
       "\\item Kansas\n",
       "\\item Kentucky\n",
       "\\item Louisiana\n",
       "\\item Maine\n",
       "\\item Maryland\n",
       "\\item Massachusetts\n",
       "\\item Michigan\n",
       "\\item Minnesota\n",
       "\\item Mississippi\n",
       "\\item Missouri\n",
       "\\item Montana\n",
       "\\item Nebraska\n",
       "\\item Nevada\n",
       "\\item New Hampshire\n",
       "\\item New Jersey\n",
       "\\item New Mexico\n",
       "\\item New York\n",
       "\\item North Carolina\n",
       "\\item North Dakota\n",
       "\\item Ohio\n",
       "\\item Oklahoma\n",
       "\\item Oregon\n",
       "\\item Pennsylvania\n",
       "\\item Rhode Island\n",
       "\\item South Carolina\n",
       "\\item South Dakota\n",
       "\\item Tennessee\n",
       "\\item Texas\n",
       "\\item Utah\n",
       "\\item Virginia\n",
       "\\item Washington\n",
       "\\item West Virginia\n",
       "\\item Wisconsin\n",
       "\\end{enumerate*}\n",
       "\n",
       "\\emph{Levels}: \\begin{enumerate*}\n",
       "\\item 'Alabama'\n",
       "\\item 'Alaska'\n",
       "\\item 'Arizona'\n",
       "\\item 'Arkansas'\n",
       "\\item 'California'\n",
       "\\item 'Colorado'\n",
       "\\item 'Connecticut'\n",
       "\\item 'Delaware'\n",
       "\\item 'Florida'\n",
       "\\item 'Georgia'\n",
       "\\item 'Hawaii'\n",
       "\\item 'Idaho'\n",
       "\\item 'Illinois'\n",
       "\\item 'Indiana'\n",
       "\\item 'Iowa'\n",
       "\\item 'Kansas'\n",
       "\\item 'Kentucky'\n",
       "\\item 'Louisiana'\n",
       "\\item 'Maine'\n",
       "\\item 'Maryland'\n",
       "\\item 'Massachusetts'\n",
       "\\item 'Michigan'\n",
       "\\item 'Minnesota'\n",
       "\\item 'Mississippi'\n",
       "\\item 'Missouri'\n",
       "\\item 'Montana'\n",
       "\\item 'Nebraska'\n",
       "\\item 'Nevada'\n",
       "\\item 'New Hampshire'\n",
       "\\item 'New Jersey'\n",
       "\\item 'New Mexico'\n",
       "\\item 'New York'\n",
       "\\item 'North Carolina'\n",
       "\\item 'North Dakota'\n",
       "\\item 'Ohio'\n",
       "\\item 'Oklahoma'\n",
       "\\item 'Oregon'\n",
       "\\item 'Pennsylvania'\n",
       "\\item 'Rhode Island'\n",
       "\\item 'South Carolina'\n",
       "\\item 'South Dakota'\n",
       "\\item 'Tennessee'\n",
       "\\item 'Texas'\n",
       "\\item 'Utah'\n",
       "\\item 'Vermont'\n",
       "\\item 'Virginia'\n",
       "\\item 'Washington'\n",
       "\\item 'West Virginia'\n",
       "\\item 'Wisconsin'\n",
       "\\item 'Wyoming'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. Arizona\n",
       "2. Arkansas\n",
       "3. California\n",
       "4. Colorado\n",
       "5. Connecticut\n",
       "6. Florida\n",
       "7. Georgia\n",
       "8. Hawaii\n",
       "9. Idaho\n",
       "10. Illinois\n",
       "11. Indiana\n",
       "12. Iowa\n",
       "13. Kansas\n",
       "14. Kentucky\n",
       "15. Louisiana\n",
       "16. Maine\n",
       "17. Maryland\n",
       "18. Massachusetts\n",
       "19. Michigan\n",
       "20. Minnesota\n",
       "21. Mississippi\n",
       "22. Missouri\n",
       "23. Montana\n",
       "24. Nebraska\n",
       "25. Nevada\n",
       "26. New Hampshire\n",
       "27. New Jersey\n",
       "28. New Mexico\n",
       "29. New York\n",
       "30. North Carolina\n",
       "31. North Dakota\n",
       "32. Ohio\n",
       "33. Oklahoma\n",
       "34. Oregon\n",
       "35. Pennsylvania\n",
       "36. Rhode Island\n",
       "37. South Carolina\n",
       "38. South Dakota\n",
       "39. Tennessee\n",
       "40. Texas\n",
       "41. Utah\n",
       "42. Virginia\n",
       "43. Washington\n",
       "44. West Virginia\n",
       "45. Wisconsin\n",
       "\n",
       "\n",
       "\n",
       "**Levels**: 1. 'Alabama'\n",
       "2. 'Alaska'\n",
       "3. 'Arizona'\n",
       "4. 'Arkansas'\n",
       "5. 'California'\n",
       "6. 'Colorado'\n",
       "7. 'Connecticut'\n",
       "8. 'Delaware'\n",
       "9. 'Florida'\n",
       "10. 'Georgia'\n",
       "11. 'Hawaii'\n",
       "12. 'Idaho'\n",
       "13. 'Illinois'\n",
       "14. 'Indiana'\n",
       "15. 'Iowa'\n",
       "16. 'Kansas'\n",
       "17. 'Kentucky'\n",
       "18. 'Louisiana'\n",
       "19. 'Maine'\n",
       "20. 'Maryland'\n",
       "21. 'Massachusetts'\n",
       "22. 'Michigan'\n",
       "23. 'Minnesota'\n",
       "24. 'Mississippi'\n",
       "25. 'Missouri'\n",
       "26. 'Montana'\n",
       "27. 'Nebraska'\n",
       "28. 'Nevada'\n",
       "29. 'New Hampshire'\n",
       "30. 'New Jersey'\n",
       "31. 'New Mexico'\n",
       "32. 'New York'\n",
       "33. 'North Carolina'\n",
       "34. 'North Dakota'\n",
       "35. 'Ohio'\n",
       "36. 'Oklahoma'\n",
       "37. 'Oregon'\n",
       "38. 'Pennsylvania'\n",
       "39. 'Rhode Island'\n",
       "40. 'South Carolina'\n",
       "41. 'South Dakota'\n",
       "42. 'Tennessee'\n",
       "43. 'Texas'\n",
       "44. 'Utah'\n",
       "45. 'Vermont'\n",
       "46. 'Virginia'\n",
       "47. 'Washington'\n",
       "48. 'West Virginia'\n",
       "49. 'Wisconsin'\n",
       "50. 'Wyoming'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " [1] Arizona        Arkansas       California     Colorado       Connecticut   \n",
       " [6] Florida        Georgia        Hawaii         Idaho          Illinois      \n",
       "[11] Indiana        Iowa           Kansas         Kentucky       Louisiana     \n",
       "[16] Maine          Maryland       Massachusetts  Michigan       Minnesota     \n",
       "[21] Mississippi    Missouri       Montana        Nebraska       Nevada        \n",
       "[26] New Hampshire  New Jersey     New Mexico     New York       North Carolina\n",
       "[31] North Dakota   Ohio           Oklahoma       Oregon         Pennsylvania  \n",
       "[36] Rhode Island   South Carolina South Dakota   Tennessee      Texas         \n",
       "[41] Utah           Virginia       Washington     West Virginia  Wisconsin     \n",
       "50 Levels: Alabama Alaska Arizona Arkansas California Colorado ... Wyoming"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## perform a train-test split\n",
    "train = subset(poll, Year <= 2008 & Year >= 2004 )\n",
    "test = subset(poll, Year == 2012  )\n",
    "    str(train)\n",
    "    summary(train)\n",
    "    str(test)\n",
    "    summary(test)\n",
    "    test$State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'data.frame':\t50 obs. of  7 variables:\n",
      " $ State     : Factor w/ 50 levels \"Alabama\",\"Alaska\",..: 1 2 3 4 5 6 7 8 9 10 ...\n",
      " $ Year      : int  2008 2008 2008 2008 2008 2008 2008 2008 2008 2008 ...\n",
      " $ Rasmussen : int  21 16 5 10 -27 -4 -17 -15 1 5 ...\n",
      " $ SurveyUSA : int  25 NA NA NA -24 NA -16 -30 -3 7 ...\n",
      " $ DiffCount : int  5 6 9 5 -5 -15 -4 -4 -13 9 ...\n",
      " $ PropR     : num  1 1 1 1 0 ...\n",
      " $ Republican: int  1 1 1 1 0 0 0 0 0 1 ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "        State         Year        Rasmussen        SurveyUSA      \n",
       " Alabama   : 1   Min.   :2008   Min.   :-41.00   Min.   :-33.000  \n",
       " Alaska    : 1   1st Qu.:2008   1st Qu.:-12.00   1st Qu.:-16.000  \n",
       " Arizona   : 1   Median :2008   Median :  0.00   Median : -5.500  \n",
       " Arkansas  : 1   Mean   :2008   Mean   : -0.78   Mean   : -4.536  \n",
       " California: 1   3rd Qu.:2008   3rd Qu.: 10.75   3rd Qu.:  2.500  \n",
       " Colorado  : 1   Max.   :2008   Max.   : 39.00   Max.   : 25.000  \n",
       " (Other)   :44                                   NA's   :22       \n",
       "   DiffCount         PropR          Republican  \n",
       " Min.   :-19.0   Min.   :0.0000   Min.   :0.00  \n",
       " 1st Qu.: -7.5   1st Qu.:0.0000   1st Qu.:0.00  \n",
       " Median : -1.0   Median :0.1456   Median :0.00  \n",
       " Mean   : -2.5   Mean   :0.4505   Mean   :0.44  \n",
       " 3rd Qu.:  4.0   3rd Qu.:1.0000   3rd Qu.:1.00  \n",
       " Max.   : 11.0   Max.   :1.0000   Max.   :1.00  \n",
       "                                                "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## set the baseline\n",
    "baseline = subset(poll, Year == 2008)\n",
    "str(baseline)\n",
    "summary(baseline)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "50"
      ],
      "text/latex": [
       "50"
      ],
      "text/markdown": [
       "50"
      ],
      "text/plain": [
       "[1] 50"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "45"
      ],
      "text/latex": [
       "45"
      ],
      "text/markdown": [
       "45"
      ],
      "text/plain": [
       "[1] 45"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "length(baseline$Republican)\n",
    "length(test$Republican)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   \n",
       "     0  1\n",
       "  0 24  0\n",
       "  1  2 19"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0"
      ],
      "text/latex": [
       "0"
      ],
      "text/markdown": [
       "0"
      ],
      "text/plain": [
       "[1] 0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.0952380952380952"
      ],
      "text/latex": [
       "0.0952380952380952"
      ],
      "text/markdown": [
       "0.0952380952380952"
      ],
      "text/plain": [
       "[1] 0.0952381"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.955555555555556"
      ],
      "text/latex": [
       "0.955555555555556"
      ],
      "text/markdown": [
       "0.955555555555556"
      ],
      "text/plain": [
       "[1] 0.9555556"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Baseline method\n",
    "common = intersect(baseline$State,test$State)  \n",
    "table1 = table(test[test$State %in% common,\"Republican\"], baseline[baseline$State %in% common,\"Republican\"])\n",
    "table1\n",
    "# The predicted values are the horizontal, and the true values are vertical\n",
    "\n",
    "fpr = 0\n",
    "fnr = 2/(2+19)\n",
    "accuracy = (24+19)/(24+19+2)\n",
    "fpr\n",
    "fnr\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.(b) \n",
    "A more credible baseline model would be to follow one of the polls and make a prediction. In our case, we will take the variable Rasmussen to make the prediction. Specifically, if the variable Rasmussen is positive, then the new baseline model predicts Republican will win; If negative, it predicts Democrat will win. And if the variable equals zero, the model would randomly predict which party will win.\n",
    "\n",
    "To determine the sign of the variable, you can use the function sign(). Type ?sign in R to see how to use the function.\n",
    "\n",
    "Using the table function, we can compare the new baseline prediction (from the sign of Rasmussen) and the actual results for the testing set. Please take a screen shot of the confusion matrix and compute the overall accuracy. Take the cases in which the model does not know which to select as wrong predictions. Does the new baseline model outperform the original one in overall accuracy? \n",
    "\n",
    "## Solution2.(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>Republican</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>7</th><td>1</td></tr>\n",
       "\t<tr><th scope=row>10</th><td>1</td></tr>\n",
       "\t<tr><th scope=row>13</th><td>0</td></tr>\n",
       "\t<tr><th scope=row>16</th><td>0</td></tr>\n",
       "\t<tr><th scope=row>19</th><td>0</td></tr>\n",
       "\t<tr><th scope=row>24</th><td>0</td></tr>\n",
       "\t<tr><th scope=row>27</th><td>1</td></tr>\n",
       "\t<tr><th scope=row>30</th><td>0</td></tr>\n",
       "\t<tr><th scope=row>33</th><td>1</td></tr>\n",
       "\t<tr><th scope=row>36</th><td>0</td></tr>\n",
       "\t<tr><th scope=row>39</th><td>1</td></tr>\n",
       "\t<tr><th scope=row>42</th><td>0</td></tr>\n",
       "\t<tr><th scope=row>45</th><td>1</td></tr>\n",
       "\t<tr><th scope=row>48</th><td>1</td></tr>\n",
       "\t<tr><th scope=row>51</th><td>1</td></tr>\n",
       "\t<tr><th scope=row>54</th><td>0</td></tr>\n",
       "\t<tr><th scope=row>57</th><td>0</td></tr>\n",
       "\t<tr><th scope=row>60</th><td>0</td></tr>\n",
       "\t<tr><th scope=row>63</th><td>0</td></tr>\n",
       "\t<tr><th scope=row>66</th><td>0</td></tr>\n",
       "\t<tr><th scope=row>69</th><td>1</td></tr>\n",
       "\t<tr><th scope=row>72</th><td>1</td></tr>\n",
       "\t<tr><th scope=row>75</th><td>1</td></tr>\n",
       "\t<tr><th scope=row>78</th><td>1</td></tr>\n",
       "\t<tr><th scope=row>81</th><td>0</td></tr>\n",
       "\t<tr><th scope=row>84</th><td>0</td></tr>\n",
       "\t<tr><th scope=row>87</th><td>0</td></tr>\n",
       "\t<tr><th scope=row>90</th><td>0</td></tr>\n",
       "\t<tr><th scope=row>93</th><td>0</td></tr>\n",
       "\t<tr><th scope=row>96</th><td>1</td></tr>\n",
       "\t<tr><th scope=row>99</th><td>1</td></tr>\n",
       "\t<tr><th scope=row>102</th><td>0</td></tr>\n",
       "\t<tr><th scope=row>105</th><td>1</td></tr>\n",
       "\t<tr><th scope=row>108</th><td>0</td></tr>\n",
       "\t<tr><th scope=row>111</th><td>0</td></tr>\n",
       "\t<tr><th scope=row>114</th><td>0</td></tr>\n",
       "\t<tr><th scope=row>117</th><td>1</td></tr>\n",
       "\t<tr><th scope=row>120</th><td>1</td></tr>\n",
       "\t<tr><th scope=row>123</th><td>1</td></tr>\n",
       "\t<tr><th scope=row>126</th><td>1</td></tr>\n",
       "\t<tr><th scope=row>129</th><td>1</td></tr>\n",
       "\t<tr><th scope=row>134</th><td>0</td></tr>\n",
       "\t<tr><th scope=row>137</th><td>0</td></tr>\n",
       "\t<tr><th scope=row>140</th><td>1</td></tr>\n",
       "\t<tr><th scope=row>143</th><td>0</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|l}\n",
       "  & Republican\\\\\n",
       "\\hline\n",
       "\t7 & 1\\\\\n",
       "\t10 & 1\\\\\n",
       "\t13 & 0\\\\\n",
       "\t16 & 0\\\\\n",
       "\t19 & 0\\\\\n",
       "\t24 & 0\\\\\n",
       "\t27 & 1\\\\\n",
       "\t30 & 0\\\\\n",
       "\t33 & 1\\\\\n",
       "\t36 & 0\\\\\n",
       "\t39 & 1\\\\\n",
       "\t42 & 0\\\\\n",
       "\t45 & 1\\\\\n",
       "\t48 & 1\\\\\n",
       "\t51 & 1\\\\\n",
       "\t54 & 0\\\\\n",
       "\t57 & 0\\\\\n",
       "\t60 & 0\\\\\n",
       "\t63 & 0\\\\\n",
       "\t66 & 0\\\\\n",
       "\t69 & 1\\\\\n",
       "\t72 & 1\\\\\n",
       "\t75 & 1\\\\\n",
       "\t78 & 1\\\\\n",
       "\t81 & 0\\\\\n",
       "\t84 & 0\\\\\n",
       "\t87 & 0\\\\\n",
       "\t90 & 0\\\\\n",
       "\t93 & 0\\\\\n",
       "\t96 & 1\\\\\n",
       "\t99 & 1\\\\\n",
       "\t102 & 0\\\\\n",
       "\t105 & 1\\\\\n",
       "\t108 & 0\\\\\n",
       "\t111 & 0\\\\\n",
       "\t114 & 0\\\\\n",
       "\t117 & 1\\\\\n",
       "\t120 & 1\\\\\n",
       "\t123 & 1\\\\\n",
       "\t126 & 1\\\\\n",
       "\t129 & 1\\\\\n",
       "\t134 & 0\\\\\n",
       "\t137 & 0\\\\\n",
       "\t140 & 1\\\\\n",
       "\t143 & 0\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | Republican | \n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| 7 | 1 | \n",
       "| 10 | 1 | \n",
       "| 13 | 0 | \n",
       "| 16 | 0 | \n",
       "| 19 | 0 | \n",
       "| 24 | 0 | \n",
       "| 27 | 1 | \n",
       "| 30 | 0 | \n",
       "| 33 | 1 | \n",
       "| 36 | 0 | \n",
       "| 39 | 1 | \n",
       "| 42 | 0 | \n",
       "| 45 | 1 | \n",
       "| 48 | 1 | \n",
       "| 51 | 1 | \n",
       "| 54 | 0 | \n",
       "| 57 | 0 | \n",
       "| 60 | 0 | \n",
       "| 63 | 0 | \n",
       "| 66 | 0 | \n",
       "| 69 | 1 | \n",
       "| 72 | 1 | \n",
       "| 75 | 1 | \n",
       "| 78 | 1 | \n",
       "| 81 | 0 | \n",
       "| 84 | 0 | \n",
       "| 87 | 0 | \n",
       "| 90 | 0 | \n",
       "| 93 | 0 | \n",
       "| 96 | 1 | \n",
       "| 99 | 1 | \n",
       "| 102 | 0 | \n",
       "| 105 | 1 | \n",
       "| 108 | 0 | \n",
       "| 111 | 0 | \n",
       "| 114 | 0 | \n",
       "| 117 | 1 | \n",
       "| 120 | 1 | \n",
       "| 123 | 1 | \n",
       "| 126 | 1 | \n",
       "| 129 | 1 | \n",
       "| 134 | 0 | \n",
       "| 137 | 0 | \n",
       "| 140 | 1 | \n",
       "| 143 | 0 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "    Republican\n",
       "7   1         \n",
       "10  1         \n",
       "13  0         \n",
       "16  0         \n",
       "19  0         \n",
       "24  0         \n",
       "27  1         \n",
       "30  0         \n",
       "33  1         \n",
       "36  0         \n",
       "39  1         \n",
       "42  0         \n",
       "45  1         \n",
       "48  1         \n",
       "51  1         \n",
       "54  0         \n",
       "57  0         \n",
       "60  0         \n",
       "63  0         \n",
       "66  0         \n",
       "69  1         \n",
       "72  1         \n",
       "75  1         \n",
       "78  1         \n",
       "81  0         \n",
       "84  0         \n",
       "87  0         \n",
       "90  0         \n",
       "93  0         \n",
       "96  1         \n",
       "99  1         \n",
       "102 0         \n",
       "105 1         \n",
       "108 0         \n",
       "111 0         \n",
       "114 0         \n",
       "117 1         \n",
       "120 1         \n",
       "123 1         \n",
       "126 1         \n",
       "129 1         \n",
       "134 0         \n",
       "137 0         \n",
       "140 1         \n",
       "143 0         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test['Republican']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "?sign"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.(c) \n",
    "\n",
    "As we start to think about building logistic regression models, we need to consider the possibility of multicollinearity within the independent variables. To some extent, some of the variables here are measuring the same thing. Compute the correlation among all variables except for State and Year. What do you observe? So, which independent variables would you recommend to include in the logistic regression model? \n",
    "\n",
    "## Solution 2.(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[-c(0:2) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'data.frame':\t100 obs. of  5 variables:\n",
      " $ Rasmussen : int  11 21 NA 16 5 5 7 10 -11 -27 ...\n",
      " $ SurveyUSA : int  18 25 NA NA 15 NA 5 NA -11 -24 ...\n",
      " $ DiffCount : int  5 5 1 6 8 9 8 5 -8 -5 ...\n",
      " $ PropR     : num  1 1 1 1 1 1 1 1 0 0 ...\n",
      " $ Republican: int  1 1 1 1 1 1 1 1 0 0 ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "   Rasmussen          SurveyUSA          DiffCount          PropR       \n",
       " Min.   :-41.0000   Min.   :-33.0000   Min.   :-19.00   Min.   :0.0000  \n",
       " 1st Qu.:-10.0000   1st Qu.:-11.0000   1st Qu.: -5.25   1st Qu.:0.0000  \n",
       " Median :  1.0000   Median : -1.0000   Median :  1.00   Median :0.6458  \n",
       " Mean   :  0.2467   Mean   :  0.1579   Mean   : -0.88   Mean   :0.5383  \n",
       " 3rd Qu.:  9.0000   3rd Qu.: 12.0000   3rd Qu.:  4.00   3rd Qu.:1.0000  \n",
       " Max.   : 39.0000   Max.   : 30.0000   Max.   : 11.00   Max.   :1.0000  \n",
       " NA's   :23         NA's   :43                                          \n",
       "   Republican  \n",
       " Min.   :0.00  \n",
       " 1st Qu.:0.00  \n",
       " Median :1.00  \n",
       " Mean   :0.53  \n",
       " 3rd Qu.:1.00  \n",
       " Max.   :1.00  \n",
       "               "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "str(train)\n",
    "summary(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>Rasmussen</th><th scope=col>SurveyUSA</th><th scope=col>DiffCount</th><th scope=col>PropR</th><th scope=col>Republican</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>Rasmussen</th><td> 1       </td><td>NA       </td><td>       NA</td><td>       NA</td><td>       NA</td></tr>\n",
       "\t<tr><th scope=row>SurveyUSA</th><td>NA       </td><td> 1       </td><td>       NA</td><td>       NA</td><td>       NA</td></tr>\n",
       "\t<tr><th scope=row>DiffCount</th><td>NA       </td><td>NA       </td><td>1.0000000</td><td>0.8273785</td><td>0.8092777</td></tr>\n",
       "\t<tr><th scope=row>PropR</th><td>NA       </td><td>NA       </td><td>0.8273785</td><td>1.0000000</td><td>0.9484204</td></tr>\n",
       "\t<tr><th scope=row>Republican</th><td>NA       </td><td>NA       </td><td>0.8092777</td><td>0.9484204</td><td>1.0000000</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllll}\n",
       "  & Rasmussen & SurveyUSA & DiffCount & PropR & Republican\\\\\n",
       "\\hline\n",
       "\tRasmussen &  1        & NA        &        NA &        NA &        NA\\\\\n",
       "\tSurveyUSA & NA        &  1        &        NA &        NA &        NA\\\\\n",
       "\tDiffCount & NA        & NA        & 1.0000000 & 0.8273785 & 0.8092777\\\\\n",
       "\tPropR & NA        & NA        & 0.8273785 & 1.0000000 & 0.9484204\\\\\n",
       "\tRepublican & NA        & NA        & 0.8092777 & 0.9484204 & 1.0000000\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | Rasmussen | SurveyUSA | DiffCount | PropR | Republican | \n",
       "|---|---|---|---|---|\n",
       "| Rasmussen |  1        | NA        |        NA |        NA |        NA | \n",
       "| SurveyUSA | NA        |  1        |        NA |        NA |        NA | \n",
       "| DiffCount | NA        | NA        | 1.0000000 | 0.8273785 | 0.8092777 | \n",
       "| PropR | NA        | NA        | 0.8273785 | 1.0000000 | 0.9484204 | \n",
       "| Republican | NA        | NA        | 0.8092777 | 0.9484204 | 1.0000000 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "           Rasmussen SurveyUSA DiffCount PropR     Republican\n",
       "Rasmussen   1        NA               NA        NA        NA \n",
       "SurveyUSA  NA         1               NA        NA        NA \n",
       "DiffCount  NA        NA        1.0000000 0.8273785 0.8092777 \n",
       "PropR      NA        NA        0.8273785 1.0000000 0.9484204 \n",
       "Republican NA        NA        0.8092777 0.9484204 1.0000000 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cor(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I would recommend 'Rasmussen','SurveyUSA' and 'PropR'\n",
    "\n",
    "## 2.(d) \n",
    "\n",
    "Build a logistic regression model using the independent variables you recommend in part (c). Provide a screen shot of the summary of the model, and interpret the estimated coefficients of the independent variables.\n",
    "\n",
    "## Solution 2.(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "         State         Year        Rasmussen          SurveyUSA       \n",
       " Arizona    : 2   Min.   :2004   Min.   :-41.0000   Min.   :-33.0000  \n",
       " Arkansas   : 2   1st Qu.:2004   1st Qu.: -9.0000   1st Qu.:-11.0000  \n",
       " California : 2   Median :2006   Median :  1.0000   Median : -2.0000  \n",
       " Colorado   : 2   Mean   :2006   Mean   : -0.1268   Mean   : -0.4717  \n",
       " Connecticut: 2   3rd Qu.:2008   3rd Qu.:  7.5000   3rd Qu.:  8.0000  \n",
       " Florida    : 2   Max.   :2008   Max.   : 39.0000   Max.   : 30.0000  \n",
       " (Other)    :78                  NA's   :19         NA's   :37        \n",
       "   DiffCount         PropR          Republican    \n",
       " Min.   :-19.0   Min.   :0.0000   Min.   :0.0000  \n",
       " 1st Qu.: -6.0   1st Qu.:0.0000   1st Qu.:0.0000  \n",
       " Median :  1.0   Median :0.6250   Median :1.0000  \n",
       " Mean   : -1.1   Mean   :0.5314   Mean   :0.5222  \n",
       " 3rd Qu.:  4.0   3rd Qu.:1.0000   3rd Qu.:1.0000  \n",
       " Max.   : 11.0   Max.   :1.0000   Max.   :1.0000  \n",
       "                                                  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "glm(formula = Republican ~ Rasmussen + SurveyUSA + PropR, family = \"binomial\", \n",
       "    data = train)\n",
       "\n",
       "Deviance Residuals: \n",
       "     Min        1Q    Median        3Q       Max  \n",
       "-1.80174  -0.00838  -0.00241   0.01510   1.10234  \n",
       "\n",
       "Coefficients:\n",
       "            Estimate Std. Error z value Pr(>|z|)\n",
       "(Intercept)  -6.3554     4.8935  -1.299    0.194\n",
       "Rasmussen     0.2862     1.0494   0.273    0.785\n",
       "SurveyUSA     0.1558     0.6858   0.227    0.820\n",
       "PropR        11.0401     8.2567   1.337    0.181\n",
       "\n",
       "(Dispersion parameter for binomial family taken to be 1)\n",
       "\n",
       "    Null deviance: 60.5711  on 44  degrees of freedom\n",
       "Residual deviance:  5.7222  on 41  degrees of freedom\n",
       "  (45 observations deleted due to missingness)\n",
       "AIC: 13.722\n",
       "\n",
       "Number of Fisher Scoring iterations: 10\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train = subset(poll, Year <= 2008 & Year >= 2004 )\n",
    "test = subset(poll, Year == 2012  )\n",
    "temp = intersect(train$State,test$State)\n",
    "train = subset(train,State%in%temp)\n",
    "test = subset(test,State%in%temp)\n",
    "summary(train)\n",
    "\n",
    "\n",
    "\n",
    "model1 = glm(Republican ~ Rasmussen + SurveyUSA + PropR, data=train,family = \"binomial\")\n",
    "summary(model1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.(e) \n",
    "\n",
    "Build a classifier based on the logistic regression model built in part (d) (we set the threshold at t =0.5,since we do not have a preference between false positives and false negatives). Show the confusion matrix and compute the overall accuracy for the testing data set. Does your model perform better (on the testing set) than the two baseline models in terms of overall accuracy? \n",
    "\n",
    "## Solution 2.(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n",
       "0.000000 0.000017 0.003323 0.400000 0.998988 1.000000 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "   \n",
       "    FALSE TRUE\n",
       "  0    19    5\n",
       "  1     7   14"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.733333333333333"
      ],
      "text/latex": [
       "0.733333333333333"
      ],
      "text/markdown": [
       "0.733333333333333"
      ],
      "text/plain": [
       "[1] 0.7333333"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = predict(model1, type=\"response\")\n",
    "summary(y_pred)\n",
    "\n",
    "\n",
    "# Confusion matrix for threshold of 0.5\n",
    "table(test$Republican,y_pred > 0.5)\n",
    "accuracy = (19+14)/(19+14+7+5)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
