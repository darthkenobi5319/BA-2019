{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import necessary Python packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the healthcare claim data\n",
    "claim = pd.read_csv(\"ClaimsData.csv\")\n",
    "claim_data = np.array(claim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>alzheimers</th>\n",
       "      <th>arthritis</th>\n",
       "      <th>cancer</th>\n",
       "      <th>copd</th>\n",
       "      <th>depression</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>heart.failure</th>\n",
       "      <th>ihd</th>\n",
       "      <th>kidney</th>\n",
       "      <th>osteoporosis</th>\n",
       "      <th>stroke</th>\n",
       "      <th>reimbursement2008</th>\n",
       "      <th>bucket2008</th>\n",
       "      <th>reimbursement2009</th>\n",
       "      <th>bucket2009</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>67</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  alzheimers  arthritis  cancer  copd  depression  diabetes  \\\n",
       "0   85           0          0       0     0           0         0   \n",
       "1   59           0          0       0     0           0         0   \n",
       "2   67           0          0       0     0           0         0   \n",
       "3   52           0          0       0     0           0         0   \n",
       "4   67           0          0       0     0           0         0   \n",
       "\n",
       "   heart.failure  ihd  kidney  osteoporosis  stroke  reimbursement2008  \\\n",
       "0              0    0       0             0       0                  0   \n",
       "1              0    0       0             0       0                  0   \n",
       "2              0    0       0             0       0                  0   \n",
       "3              0    0       0             0       0                  0   \n",
       "4              0    0       0             0       0                  0   \n",
       "\n",
       "   bucket2008  reimbursement2009  bucket2009  \n",
       "0           1                  0           1  \n",
       "1           1                  0           1  \n",
       "2           1                  0           1  \n",
       "3           1                  0           1  \n",
       "4           1                  0           1  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "claim.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(458005, 16)\n"
     ]
    }
   ],
   "source": [
    "print(claim_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "##For the covariates, we should remove the 2019 reimbursement amount information\n",
    "X = claim_data[:,0:-2]\n",
    "y = claim_data[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(458005, 14)\n",
      "(458005,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Split the data into training (75%) and testing (25%) data sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state= 88)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Build the classification tree \n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[68887  4888  2073   919   121]\n",
      " [ 9930  6735  2936  1806   360]\n",
      " [ 4366  2861  1710  1061   212]\n",
      " [ 1719  1224   854   944   242]\n",
      " [  188   117   108   180    61]]\n",
      "0.6841539885766188\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "##Baseline model: Use the cost bucket of 2008 directly to predict the outcome of 2019\n",
    "CM_baseline = confusion_matrix(y_test, X_test[:,13])\n",
    "print(CM_baseline)\n",
    "print(accuracy_score(y_test,  X_test[:,13]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input the penalty matrix\n",
    "penalty = np.array([[0,1,2,3,4],[2,0,1,2,3],[4,2,0,1,2],[6,4,2,0,1],[8,6,4,2,0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 2 3 4]\n",
      " [2 0 1 2 3]\n",
      " [4 2 0 1 2]\n",
      " [6 4 2 0 1]\n",
      " [8 6 4 2 0]]\n"
     ]
    }
   ],
   "source": [
    "print(penalty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7387818553387714"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Penalty Error for the baseline model\n",
    "np.sum(np.multiply(CM_baseline,penalty))/np.sum(CM_baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build a classification tree to fit the trainin set. The maximum depth of the tree is set to be 4.\n",
    "tree_D2Hawkeye = DecisionTreeClassifier(max_depth=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_D2Hawkeye.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D2Hawkeye.pdf'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Print out the tree\n",
    "import graphviz\n",
    "dot_data = export_graphviz(tree_D2Hawkeye,feature_names= ['age','alzheimers','arthritis','cancer','copd','depression','diabetes','heart.failure','ihd','kidney','osteoporosis','stroke','reimbursement2008','bucket2008'], class_names = ['1','2','3','4','5']) \n",
    "tree_graph = graphviz.Source(dot_data) \n",
    "tree_graph.render(\"D2Hawkeye\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make predictions on the testing data set\n",
    "y_predict = tree_D2Hawkeye.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[72831  4057     0     0     0]\n",
      " [13017  8750     0     0     0]\n",
      " [ 5705  4505     0     0     0]\n",
      " [ 2234  2749     0     0     0]\n",
      " [  241   413     0     0     0]]\n"
     ]
    }
   ],
   "source": [
    "#create the confusion matrix on the out-of-sample test\n",
    "CM_tree = confusion_matrix(y_test, y_predict)\n",
    "print(CM_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7124853714345601\n"
     ]
    }
   ],
   "source": [
    "#The testing overall accuracy\n",
    "print(accuracy_score(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7923617054723935"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Penalty Error for the tree model\n",
    "np.sum(np.multiply(CM_tree,penalty))/np.sum(CM_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 6}\n",
      "Best Overal Accuracy: 0.71\n"
     ]
    }
   ],
   "source": [
    "#Cross-validated Parameter tuning for the maximum depth of the tree\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'max_depth':range(1, 7)}\n",
    "grid = GridSearchCV(DecisionTreeClassifier(random_state=0),param_grid=param_grid,cv=10)\n",
    "grid.fit(X_train, y_train)\n",
    "print(grid.best_params_)\n",
    "print('Best Overal Accuracy: %.2f' %grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8448339606932108, 0.9275610402238117, 0.9511561762197128, 0.9573511730610795, 0.9615490985522688, 0.9630949365798843, 0.9640847387067945, 0.9645097713848205, 0.9650163171791803, 0.9651414980364073, 0.9653860373854086, 0.9654733728671947, 0.9655548859835286, 0.9656655109271244, 0.9656829780234816, 0.9656655109271244, 0.9657382904952795, 0.9657353793125533, 0.9657615799570891, 0.965758668774363]\n",
      "[0.6307226074653718, 0.6625648460288903, 0.663324658084575, 0.6636215961293253, 0.6645648110950028, 0.664800614836422, 0.6656477616111509, 0.6657525632740039, 0.6647482140049955, 0.6647744144207088, 0.6652023545440254, 0.6651412202406944, 0.6663726397792178, 0.6657525632740039, 0.6665647761611151, 0.6664250406106443, 0.6660582347906587, 0.667018916700145, 0.6664512410263577, 0.6669839828125272]\n"
     ]
    }
   ],
   "source": [
    "## Fit a random-forest model with different numbers of trees (estimators) in the forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "estimator_range = range(1, 100, 5)##Number of trees in the forest\n",
    "\n",
    "for n_estimators in estimator_range:\n",
    "    rf.n_estimators = n_estimators\n",
    "    rf.fit(X_train, y_train)\n",
    "    train_scores.append(rf.score(X_train, y_train))\n",
    "    test_scores.append(rf.score(X_test, y_test))\n",
    "    \n",
    "print(train_scores)\n",
    "print(test_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.28497675, 0.01491678, 0.01559512, 0.00896458, 0.01289003,\n",
       "       0.01258243, 0.03047576, 0.02327335, 0.03098938, 0.01876693,\n",
       "       0.01420838, 0.00879899, 0.46011042, 0.06345109])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## The importance of different features for a random forest of 100 trees\n",
    "\n",
    "rf2=RandomForestClassifier(n_estimators=100).fit(X_train, y_train)\n",
    "rf2.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6345884564889053"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load the boston housing data set and necessary models\n",
    "\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import StandardScaler ##The scaling tool\n",
    "\n",
    "boston = load_boston()\n",
    "Xb = boston.data \n",
    "yb = boston.target\n",
    "Xb_train, Xb_test, yb_train, yb_test = train_test_split(\n",
    "    Xb, yb, random_state=0,test_size=0.25)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(Xb_train)\n",
    "\n",
    "Xb_train_scaled = scaler.transform(Xb_train)\n",
    "ridge = Ridge().fit(Xb_train_scaled, yb_train)\n",
    "\n",
    "Xb_test_scaled = scaler.transform(Xb_test)\n",
    "\n",
    "\n",
    "ridge.score(Xb_test_scaled, yb_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6345884564889053"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Combine transformation, model fit, and prediction together using pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "pipe = make_pipeline(StandardScaler(), Ridge())\n",
    "pipe.fit(Xb_train, yb_train)\n",
    "pipe.score(Xb_test, yb_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kneighborsregressor__n_neighbors': 7}\n",
      "0.5999825126971097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rz26/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#Pipeline meets grid-search cross validation to find the best number of neighbors for k-nearest neighbors regressor\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "knn_pipe = make_pipeline(StandardScaler(), KNeighborsRegressor())\n",
    "param_grid = {'kneighborsregressor__n_neighbors': range(1, 10)}\n",
    "grid = GridSearchCV(knn_pipe, param_grid, cv=10)\n",
    "grid.fit(Xb_train, yb_train)\n",
    "print(grid.best_params_)\n",
    "print(grid.score(Xb_test, yb_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6696430114132679"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Include the polynomial features when fitting the model\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "poly_pipe = make_pipeline(PolynomialFeatures(degree=2), Ridge())\n",
    "\n",
    "poly_pipe.fit(Xb_train_scaled, yb_train)\n",
    "poly_pipe.score(Xb_test_scaled, yb_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[     0 230556  65332  30766  14860   1989]\n",
      "[    0 76888 21767 10210  4983   654]\n"
     ]
    }
   ],
   "source": [
    "##Imbalancedness of the D2Hawkeye data set\n",
    "print(np.bincount(y_train))\n",
    "print(np.bincount(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(343503, 14)\n",
      "(9945, 14)\n",
      "[   0 1989 1989 1989 1989 1989]\n"
     ]
    }
   ],
   "source": [
    "##Undersampling\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "rus = RandomUnderSampler(replacement=False)\n",
    "X_train_subsample, y_train_subsample = rus.fit_sample(\n",
    "    X_train, y_train)\n",
    "print(X_train.shape)\n",
    "print(X_train_subsample.shape)\n",
    "print(np.bincount(y_train_subsample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=4,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Fit a CART model using the under sampled data\n",
    "tree_D2Hawkeye.fit(X_train_subsample, y_train_subsample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[49015 21748  4346   777  1002]\n",
      " [ 2284 12050  4216   877  2340]\n",
      " [ 1182  5080  2085   428  1435]\n",
      " [  451  1971  1026   199  1336]\n",
      " [   43   212   110    21   268]]\n",
      "0.5555972821435433\n"
     ]
    }
   ],
   "source": [
    "#Examining the effect of undersampling \n",
    "\n",
    "y_predict = tree_D2Hawkeye.predict(X_test)\n",
    "CM_tree_subsample = confusion_matrix(y_test, y_predict)\n",
    "print(CM_tree_subsample)\n",
    "print(accuracy_score(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(343503, 14)\n",
      "(1152780, 14)\n",
      "[     0 230556 230556 230556 230556 230556]\n"
     ]
    }
   ],
   "source": [
    "##Oversampling\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "ros = RandomOverSampler()\n",
    "X_train_oversample, y_train_oversample = ros.fit_sample(X_train, y_train)\n",
    "print(X_train.shape)\n",
    "print(X_train_oversample.shape)\n",
    "print(np.bincount(y_train_oversample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[61304 11150  2720   262  1452]\n",
      " [ 5421  8980  4125   471  2770]\n",
      " [ 2599  3708  2028   253  1622]\n",
      " [ 1003  1439  1001   120  1420]\n",
      " [  103   156   106    11   278]]\n",
      "0.6350107421704424\n"
     ]
    }
   ],
   "source": [
    "##Fit the decision tree model with the over-sampled data and examine its effectiveness on the testing data\n",
    "\n",
    "tree_D2Hawkeye.fit(X_train_oversample, y_train_oversample)\n",
    "y_predict = tree_D2Hawkeye.predict(X_test)\n",
    "CM_tree_oversample = confusion_matrix(y_test, y_predict)\n",
    "print(CM_tree_oversample)\n",
    "print(accuracy_score(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rz26/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/rz26/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/rz26/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(343503, 14)\n",
      "(1152780, 14)\n",
      "[     0 230556 230556 230556 230556 230556]\n"
     ]
    }
   ],
   "source": [
    "##SMOTE sampling method\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "smt = SMOTE()\n",
    "\n",
    "##Standardize the covariates for the training and testing data\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "X_train_SMOTE, y_train_SMOTE = smt.fit_sample(X_train_scaled, y_train)\n",
    "print(X_train_scaled.shape)\n",
    "print(X_train_SMOTE.shape)\n",
    "print(np.bincount(y_train_SMOTE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[56956 19256     0     0   676]\n",
      " [ 3918 16190     0     0  1659]\n",
      " [ 1956  7216     0     0  1038]\n",
      " [  732  3182     0     0  1069]\n",
      " [   78   351     0     0   225]]\n",
      "0.6407835670992647\n"
     ]
    }
   ],
   "source": [
    "#Train the decision tree model on the training set with SMOTE and test it over the testing set\n",
    "tree_D2Hawkeye.fit(X_train_SMOTE, y_train_SMOTE)\n",
    "y_predict = tree_D2Hawkeye.predict(X_test_scaled)\n",
    "CM_tree_SMOTE = confusion_matrix(y_test, y_predict)\n",
    "print(CM_tree_SMOTE)\n",
    "print(accuracy_score(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
