{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import necessary Python packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the healthcare claim data\n",
    "claim = pd.read_csv(\"D:/Study/Business Analytics/LA/2019.3.4/ClaimsData(1).csv\")\n",
    "claim_data = np.array(claim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>alzheimers</th>\n",
       "      <th>arthritis</th>\n",
       "      <th>cancer</th>\n",
       "      <th>copd</th>\n",
       "      <th>depression</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>heart.failure</th>\n",
       "      <th>ihd</th>\n",
       "      <th>kidney</th>\n",
       "      <th>osteoporosis</th>\n",
       "      <th>stroke</th>\n",
       "      <th>reimbursement2008</th>\n",
       "      <th>bucket2008</th>\n",
       "      <th>reimbursement2009</th>\n",
       "      <th>bucket2009</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>67</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  alzheimers  arthritis  cancer  copd  depression  diabetes  \\\n",
       "0   85           0          0       0     0           0         0   \n",
       "1   59           0          0       0     0           0         0   \n",
       "2   67           0          0       0     0           0         0   \n",
       "3   52           0          0       0     0           0         0   \n",
       "4   67           0          0       0     0           0         0   \n",
       "\n",
       "   heart.failure  ihd  kidney  osteoporosis  stroke  reimbursement2008  \\\n",
       "0              0    0       0             0       0                  0   \n",
       "1              0    0       0             0       0                  0   \n",
       "2              0    0       0             0       0                  0   \n",
       "3              0    0       0             0       0                  0   \n",
       "4              0    0       0             0       0                  0   \n",
       "\n",
       "   bucket2008  reimbursement2009  bucket2009  \n",
       "0           1                  0           1  \n",
       "1           1                  0           1  \n",
       "2           1                  0           1  \n",
       "3           1                  0           1  \n",
       "4           1                  0           1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "claim.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(458005, 16)\n"
     ]
    }
   ],
   "source": [
    "print(claim_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "##For the covariates, we should remove the 2019 reimbursement amount information\n",
    "X = claim_data[:,0:-2]\n",
    "y = claim_data[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The slicing with indices follows the following principle:\n",
    "\n",
    "For example, y = claim_data[:,-1] means we want all the rows and the last column.\n",
    "\n",
    "And,X = claim_data[:,0:-2] means we want all the rows, and the columns from the first to the third to last(i.e. bucket2008)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(458005, 14)\n",
      "(458005,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Split the data into training (75%) and testing (25%) data sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state= 88)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Build the classification tree \n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### confusion_matrix(A, B) works the same as the table(A,B) in R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[68887  4888  2073   919   121]\n",
      " [ 9930  6735  2936  1806   360]\n",
      " [ 4366  2861  1710  1061   212]\n",
      " [ 1719  1224   854   944   242]\n",
      " [  188   117   108   180    61]]\n",
      "0.6841539885766188\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "## Baseline model: Use the cost bucket of 2008 directly to predict the outcome of 2019\n",
    "CM_baseline = confusion_matrix(y_test, X_test[:,13])\n",
    "print(CM_baseline)\n",
    "print(accuracy_score(y_test,  X_test[:,13]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input the penalty matrix\n",
    "penalty = np.array([[0,1,2,3,4],[2,0,1,2,3],[4,2,0,1,2],[6,4,2,0,1],[8,6,4,2,0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 2 3 4]\n",
      " [2 0 1 2 3]\n",
      " [4 2 0 1 2]\n",
      " [6 4 2 0 1]\n",
      " [8 6 4 2 0]]\n"
     ]
    }
   ],
   "source": [
    "print(penalty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7387818553387714"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Penalty Error for the baseline model\n",
    "np.sum(np.multiply(CM_baseline,penalty))/np.sum(CM_baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the DecisionTreeClassifier(max_depth=x) as the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build a classification tree to fit the trainin set. The maximum depth of the tree is set to be 4.\n",
    "tree_D2Hawkeye = DecisionTreeClassifier(max_depth=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_D2Hawkeye.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First, open your anaconda prompt, type:conda install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\export.py:399: DeprecationWarning: out_file can be set to None starting from 0.18. This will be the default in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command '['dot.bat', '-Tpdf', '-O', 'D2Hawkeye']' returned non-zero exit status 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-4c69d94e7b9c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdot_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexport_graphviz\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtree_D2Hawkeye\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'age'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'alzheimers'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'arthritis'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'cancer'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'copd'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'depression'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'diabetes'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'heart.failure'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'ihd'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'kidney'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'osteoporosis'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'stroke'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'reimbursement2008'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'bucket2008'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'1'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'2'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'3'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'4'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'5'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtree_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraphviz\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSource\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdot_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mtree_graph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"D2Hawkeye\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\graphviz\\files.py\u001b[0m in \u001b[0;36mrender\u001b[1;34m(self, filename, directory, view, cleanup)\u001b[0m\n\u001b[0;32m    174\u001b[0m         \u001b[0mfilepath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdirectory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 176\u001b[1;33m         \u001b[0mrendered\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_format\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    177\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcleanup\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\graphviz\\backend.py\u001b[0m in \u001b[0;36mrender\u001b[1;34m(engine, format, filepath, quiet)\u001b[0m\n\u001b[0;32m    129\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevnull\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mstderr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m             \u001b[0msubprocess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstderr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mPOPEN_KWARGS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrno\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0merrno\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mENOENT\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\subprocess.py\u001b[0m in \u001b[0;36mcheck_call\u001b[1;34m(*popenargs, **kwargs)\u001b[0m\n\u001b[0;32m    326\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcmd\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    327\u001b[0m             \u001b[0mcmd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpopenargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 328\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mCalledProcessError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mretcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    329\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mCalledProcessError\u001b[0m: Command '['dot.bat', '-Tpdf', '-O', 'D2Hawkeye']' returned non-zero exit status 1."
     ]
    }
   ],
   "source": [
    "##Print out the tree\n",
    "\n",
    "import graphviz\n",
    "dot_data = export_graphviz(tree_D2Hawkeye,feature_names= ['age','alzheimers','arthritis','cancer','copd','depression','diabetes','heart.failure','ihd','kidney','osteoporosis','stroke','reimbursement2008','bucket2008'], class_names = ['1','2','3','4','5']) \n",
    "tree_graph = graphviz.Source(dot_data) \n",
    "tree_graph.render(\"D2Hawkeye\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make predictions on the testing data set\n",
    "y_predict = tree_D2Hawkeye.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[72831  4057     0     0     0]\n",
      " [13017  8750     0     0     0]\n",
      " [ 5705  4505     0     0     0]\n",
      " [ 2234  2749     0     0     0]\n",
      " [  241   413     0     0     0]]\n"
     ]
    }
   ],
   "source": [
    "#create the confusion matrix on the out-of-sample test\n",
    "CM_tree = confusion_matrix(y_test, y_predict)\n",
    "print(CM_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7124853714345601\n"
     ]
    }
   ],
   "source": [
    "#The testing overall accuracy\n",
    "print(accuracy_score(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7923617054723935"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Penalty Error for the tree model\n",
    "np.sum(np.multiply(CM_tree,penalty))/np.sum(CM_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearchCV as we've talked about in previous notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 6}\n",
      "Best Overal Accuracy: 0.71\n"
     ]
    }
   ],
   "source": [
    "#Cross-validated Parameter tuning for the maximum depth of the tree\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'max_depth':range(1, 7)}\n",
    "grid = GridSearchCV(DecisionTreeClassifier(random_state=0),param_grid=param_grid,cv=10)\n",
    "grid.fit(X_train, y_train)\n",
    "print(grid.best_params_)\n",
    "print('Best Overal Accuracy: %.2f' %grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Then we use a random forest classifier\n",
    "\n",
    "The results are two lists, each element in the list is a score of different numbers of estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8449707862813425, 0.9270020931403802, 0.9516132319077272, 0.9575054657455685, 0.9616626346785909, 0.9630425352908126, 0.9640556268795324, 0.9645359720293564, 0.9650687184682522, 0.9652288335181934, 0.9654326163090279, 0.965490839963552, 0.9656014649071478, 0.9656131096380527, 0.9656800668407554, 0.9657062674852912, 0.9657150010334699, 0.9657528464089106, 0.9657441128607319, 0.9657615799570891]\n",
      "--------------------------------------\n",
      "[0.6302946673420552, 0.6633071911407661, 0.6612897591308449, 0.6644600094321497, 0.6639796684774065, 0.6654905591168713, 0.6651062863530768, 0.6647831478926133, 0.6654818256449669, 0.6661193690939896, 0.6657612967459083, 0.665691428970673, 0.6656652285549597, 0.6655953607797244, 0.6659971004873277, 0.6664075736668356, 0.6671586522506157, 0.6664163071387399, 0.6663988401949311, 0.6670800510034759]\n"
     ]
    }
   ],
   "source": [
    "## Fit a random-forest model with different numbers of trees (estimators) in the forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "estimator_range = range(1, 100, 5)##Number of trees in the forest\n",
    "\n",
    "for n_estimators in estimator_range:\n",
    "    rf.n_estimators = n_estimators\n",
    "    rf.fit(X_train, y_train)\n",
    "    train_scores.append(rf.score(X_train, y_train))\n",
    "    test_scores.append(rf.score(X_test, y_test))\n",
    "    \n",
    "print(train_scores)\n",
    "print('--------------------------------------')\n",
    "print(test_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.28506076, 0.01509037, 0.01455796, 0.00911884, 0.01251155,\n",
       "       0.01517363, 0.03491882, 0.02140716, 0.03421163, 0.01537969,\n",
       "       0.01408039, 0.00904827, 0.46650257, 0.05293836])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## The importance of different features for a random forest of 100 trees\n",
    "\n",
    "rf2=RandomForestClassifier(n_estimators=100).fit(X_train, y_train)\n",
    "rf2.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling is similar to fitting a model, the general method is, for example:\n",
    "\n",
    "### scaler = StandardScaler()\n",
    "\n",
    "### scaler.fit(Xb_train)\n",
    "\n",
    "### Xb_train_scaled = scaler.transform(Xb_train)\n",
    "\n",
    "### You may also use .fit_transform() for convenience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6345884564889053"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load the boston housing data set and necessary models\n",
    "\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import StandardScaler ##The scaling tool\n",
    "\n",
    "boston = load_boston()\n",
    "Xb = boston.data \n",
    "yb = boston.target\n",
    "Xb_train, Xb_test, yb_train, yb_test = train_test_split(\n",
    "    Xb, yb, random_state=0,test_size=0.25)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(Xb_train)\n",
    "\n",
    "Xb_train_scaled = scaler.transform(Xb_train)\n",
    "ridge = Ridge().fit(Xb_train_scaled, yb_train)\n",
    "\n",
    "Xb_test_scaled = scaler.transform(Xb_test)\n",
    "\n",
    "\n",
    "ridge.score(Xb_test_scaled, yb_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make_pipeline()is similar to a function: it executes all the methods you input into it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6345884564889053"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Combine transformation, model fit, and prediction together using pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "pipe = make_pipeline(StandardScaler(), Ridge())\n",
    "pipe.fit(Xb_train, yb_train)\n",
    "pipe.score(Xb_test, yb_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kneighborsregressor__n_neighbors': 7}\n",
      "0.5999825126971097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rz26/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#Pipeline meets grid-search cross validation to find the best number of neighbors for k-nearest neighbors regressor\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "knn_pipe = make_pipeline(StandardScaler(), KNeighborsRegressor())\n",
    "param_grid = {'kneighborsregressor__n_neighbors': range(1, 10)}\n",
    "grid = GridSearchCV(knn_pipe, param_grid, cv=10)\n",
    "grid.fit(Xb_train, yb_train)\n",
    "print(grid.best_params_)\n",
    "print(grid.score(Xb_test, yb_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6696430114132679"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Include the polynomial features when fitting the model\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly_pipe = make_pipeline(PolynomialFeatures(degree=2), Ridge())\n",
    "poly_pipe.fit(Xb_train_scaled, yb_train)\n",
    "poly_pipe.score(Xb_test_scaled, yb_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[     0 230556  65332  30766  14860   1989]\n",
      "[    0 76888 21767 10210  4983   654]\n"
     ]
    }
   ],
   "source": [
    "##Imbalancedness of the D2Hawkeye data set\n",
    "print(np.bincount(y_train))\n",
    "print(np.bincount(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(343503, 14)\n",
      "(9945, 14)\n",
      "[   0 1989 1989 1989 1989 1989]\n"
     ]
    }
   ],
   "source": [
    "##Undersampling\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "rus = RandomUnderSampler(replacement=False)\n",
    "X_train_subsample, y_train_subsample = rus.fit_sample(\n",
    "    X_train, y_train)\n",
    "print(X_train.shape)\n",
    "print(X_train_subsample.shape)\n",
    "print(np.bincount(y_train_subsample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=4,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Fit a CART model using the under sampled data\n",
    "tree_D2Hawkeye.fit(X_train_subsample, y_train_subsample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[49015 21748  4346   777  1002]\n",
      " [ 2284 12050  4216   877  2340]\n",
      " [ 1182  5080  2085   428  1435]\n",
      " [  451  1971  1026   199  1336]\n",
      " [   43   212   110    21   268]]\n",
      "0.5555972821435433\n"
     ]
    }
   ],
   "source": [
    "#Examining the effect of undersampling \n",
    "\n",
    "y_predict = tree_D2Hawkeye.predict(X_test)\n",
    "CM_tree_subsample = confusion_matrix(y_test, y_predict)\n",
    "print(CM_tree_subsample)\n",
    "print(accuracy_score(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(343503, 14)\n",
      "(1152780, 14)\n",
      "[     0 230556 230556 230556 230556 230556]\n"
     ]
    }
   ],
   "source": [
    "##Oversampling\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "ros = RandomOverSampler()\n",
    "X_train_oversample, y_train_oversample = ros.fit_sample(X_train, y_train)\n",
    "print(X_train.shape)\n",
    "print(X_train_oversample.shape)\n",
    "print(np.bincount(y_train_oversample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[61304 11150  2720   262  1452]\n",
      " [ 5421  8980  4125   471  2770]\n",
      " [ 2599  3708  2028   253  1622]\n",
      " [ 1003  1439  1001   120  1420]\n",
      " [  103   156   106    11   278]]\n",
      "0.6350107421704424\n"
     ]
    }
   ],
   "source": [
    "##Fit the decision tree model with the over-sampled data and examine its effectiveness on the testing data\n",
    "\n",
    "tree_D2Hawkeye.fit(X_train_oversample, y_train_oversample)\n",
    "y_predict = tree_D2Hawkeye.predict(X_test)\n",
    "CM_tree_oversample = confusion_matrix(y_test, y_predict)\n",
    "print(CM_tree_oversample)\n",
    "print(accuracy_score(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rz26/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/rz26/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/rz26/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(343503, 14)\n",
      "(1152780, 14)\n",
      "[     0 230556 230556 230556 230556 230556]\n"
     ]
    }
   ],
   "source": [
    "##SMOTE sampling method\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "smt = SMOTE()\n",
    "\n",
    "##Standardize the covariates for the training and testing data\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "X_train_SMOTE, y_train_SMOTE = smt.fit_sample(X_train_scaled, y_train)\n",
    "print(X_train_scaled.shape)\n",
    "print(X_train_SMOTE.shape)\n",
    "print(np.bincount(y_train_SMOTE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[56956 19256     0     0   676]\n",
      " [ 3918 16190     0     0  1659]\n",
      " [ 1956  7216     0     0  1038]\n",
      " [  732  3182     0     0  1069]\n",
      " [   78   351     0     0   225]]\n",
      "0.6407835670992647\n"
     ]
    }
   ],
   "source": [
    "#Train the decision tree model on the training set with SMOTE and test it over the testing set\n",
    "tree_D2Hawkeye.fit(X_train_SMOTE, y_train_SMOTE)\n",
    "y_predict = tree_D2Hawkeye.predict(X_test_scaled)\n",
    "CM_tree_SMOTE = confusion_matrix(y_test, y_predict)\n",
    "print(CM_tree_SMOTE)\n",
    "print(accuracy_score(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
